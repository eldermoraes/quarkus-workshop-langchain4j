quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}
# quarkus.langchain4j.openai.base-url=http://localhost:11434/v1

quarkus.langchain4j.openai.chat-model.model-name=gpt-4o
# quarkus.langchain4j.openai.chat-model.model-name=gpt-oss:20b

quarkus.langchain4j.openai.chat-model.log-requests=true
quarkus.langchain4j.openai.chat-model.log-responses=true

quarkus.langchain4j.openai.chat-model.temperature=1.0
quarkus.langchain4j.openai.chat-model.max-completion-tokens=1000
quarkus.langchain4j.openai.chat-model.frequency-penalty=0

quarkus.langchain4j.easy-rag.path=rag
quarkus.langchain4j.easy-rag.path-type=classpath
quarkus.langchain4j.easy-rag.max-segment-size=100
quarkus.langchain4j.easy-rag.max-overlap-size=25
quarkus.langchain4j.easy-rag.max-results=3
# quarkus.langchain4j.openai.embedding-model.model-name=nomic-embed-text:v1.5

#--8<-- [start:container-image]
quarkus.container-image.registry=docker.io
quarkus.container-image.group=eldermoraes
quarkus.container-image.name=quarkus-langchain4j-workshop
quarkus.container-image.tag=1.0-SNAPSHOT
#--8<-- [end:container-image]

#--8<-- [start:kubernetes]
quarkus.kubernetes-client.trust-certs=true
quarkus.kubernetes.service-type=ClusterIP
quarkus.kubernetes.resources.requests.cpu=250m
quarkus.kubernetes.resources.requests.memory=256Mi
quarkus.kubernetes.resources.limits.cpu=500m
quarkus.kubernetes.resources.limits.memory=512Mi
#--8<-- [end:kubernetes]